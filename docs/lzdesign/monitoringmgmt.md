# Monitoring & Management

Centralized monitoring and management of all IT and Application infrastructure, along with associated middleware and security elements is important across on-premises, hybrid and multi-cloud environments. 

Microsoftâ€™s cloud adoption framework (CAF) prescribes monitoring across Infrastructure, Applications, Security, and all cloud services utilized by a client and service provider organization. These include 

- Monitoring health, performance and security of IT resources
- Gathering and analyzing logs across all services and applications
- Gathering and analyzing metrics across all services and applications
- Extract meaningful information from the analysis, identify actionable incidents and remediate the same reactively and pro-actively

This document starts with a description of Azure functions and components that support monitoring in addition to an overview of Azure monitoring architecture and Security Management Architecture. It then proceeds to discuss Kyndryl offerings that integrate Azure monitoring into Service Management solutions. It concludes with a discussion on design considerations and recommendations for monitoring.

## Overview of Azure services for Monitoring & Management

Azure provides a comprehensive set of tools and services to monitor across infrastructure, security, cloud services and application stacks.

- Both metrics data and logs are gathered across Identity and Access Management, Azure resources, Subscriptions, Operating systems, Applications that can be integrated to other tools either through Logic Apps or APIs
- Based on evaluation of the data against certain conditions, alerts can be triggered and also, autoscaling of resources such as Virtual Machine Scale Sets can be performed
- Tools for analyzing both metrics data and logs are available
- Visualization tools for presentation of either raw data or filtered data resulting from queries are available
- Tools to create insights from the analysis of data across Virtual Machines, Containers and Applications are available.

<center><img style="height:200;width:150" src="../images/landingzone-monitoring1.png" /></center>

For cloud-native Security Information and Event Management (SIEM), Azure Sentinel should be leveraged which helps in analyzing large volumes of data across an enterprise with built-in AI. 

## Azure Monitoring Architecture
This section presents an architectural overview of the monitoring solution in Azure. The intent is to give the readers a high-level understanding of the various components involved in Monitoring and Logging across the Azure platform and services and how these components complement one another in providing a comprehensive solution. The diagram below illustrates the architecture.

<center><img style="height:200;width:150" src="../images/landingzone-monitoring2.svg" /></center>

The centerpiece of the Monitoring solution is the Azure Monitor. This consists of the Metrics component and the Logs component. 

- Metrics are numerical values. The Metrics component gathers the metrics into a fast, lightweight time series database across all those components that generate them. Metrics can be viewed in less than 60 seconds post their occurrence. The intent is to be able to react in near real time to any issue based on an analysis of these metrics. 
- The Logs component gathers both metrics and logs across all those components that generate them and can store them in different stores or targets. This is a slower process and intended more for analysis of data gathered over a period. 
- Those components that do not rely on agents send the metrics and the logs to one or more of destinations such as Log Analytics, Storage Account or Event Hub. For those that depend on agents, Log Analytics is the only possible destination.

The following sections cover in detail, the sources of metrics and logs, the target destinations they can be directed to, the visualization and analytics that can be performed on the data and the raising of alerts based on the detection of certain conditions in the data.

### Sources of data

This section briefly covers all those Azure resources that generate metrics and logs. It is to be emphasize that where metrics are generated, they are sent to both the fast time series database and the slow targets.

#### Azure Active Directory (AAD)

AAD creates a variety of logs (audit, sign-in, provisioning). AAD can be configured to direct these logs to one or more of destinations such as Log Analytics, Storage Account or Event Hub. 

#### Subscription

Each subscription generates an Activity log that encompasses actions related to the lifecycle of Azure resources. The Activity log also contains information generated by the Service Health tool that includes Resource alerts, Health issues/advisories/alerts, Planned Maintenance and Security advisories. A subscription can be configured to direct the activity log to one or more of destinations such as Log Analytics, Storage Account or Event Hub.

#### ARM Resources

Each resource generates metrics as numerical values that are unique to itself. 

Each resource also generates logs as both numerical and string values that are unique to itself. 

Note that the metrics and logs here relate to the ARM resources as known to the virtualization layer hosting them.

A resource can be configured to direct its metrics and logs to one or more of destinations such as Log Analytics, Storage Account or Event Hub.

#### Guest OS

For resources such as VMs that run Guest Operating Systems, additional metrics and logs are generated through agents running on those resources. These resources need not be just ARM resources. They could be VMs running for example on either customer premises or in other clouds. The metrics and logs from these resources can only be directed to Log Analytics.

#### Applications

Applications can be monitored either through codeless attach procedures (J2EE/.NET runtime monitoring is an example) or through compile-time instrumentation. The metrics and logs from these resources can only be directed to Log Analytics. The resulting metrics and logs can be analyzed by the App Insights tool to diagnose issues.

#### Miscellaneous sources

There are certain solutions such as Hadoop and Kubernetes clusters that generate, store, and process their metrics and logs differently. It is also possible to generate metrics and logs for custom resources through the ARM REST API. The metrics and logs from these resources can only be directed to Log Analytics.

### Destinations for data

This section briefly describes the three main possible target destinations for the metrics and logs generated by various Azure resources. Again, metrics are always sent to the time series database in addition to the targets that logs are sent to.

#### Storage Account

One potential destination for the generated metrics and logs is a storage account. The benefit of using a storage account is the low cost that enables long term storage or archival.

#### Event Hub

A second potential destination for the generated metrics and logs is an Event Hub. The benefit of this is the ability to send the data to multiple third-party solutions that can provide more sophisticated analysis of the data.

#### Log Analytics

This is a workspace that is part of the Azure Monitor Logs tool. A workspace is a combination of storage space in the form of tables and processing capabilities that allow queries to be run against the data to extract insights. In general, there is a cost to both ingestion of the data as well as the storage. By default, the data is retained for 2 years but can be configured to tradeoff cost against retention. It is also possible to cap the rate at which data is ingested. 

For those data sources that can direct their metrics and logs only to Log Analytics and not to either a Storage Account or an Event Hub, it is possible to export data on a per table basis from Log Analytics to either a Storage Account or an Event Hub. It is possible to filter the data using Logic Apps, for example, as part of the export process. An Event Hub is fed the data in near real-time while a Storage Account is updated hourly.

### Processing of data

This section covers the various tools that exist or can be created to process the data from metrics and logs for visualization and analytics.

#### Insights

These are tools to aggregate, correlate and display the data gathered for resources such as VMs, Storage, AKS, Key Vaults, Databases and Applications. They are either custom developed or workbook based. If the latter, the display can be customized. Typically, data from the metrics timeseries database, Log Analytics and activity logs are processed by the Insights.

#### Dashboards

These are tools that provide a single pane of glass across multiple resources and their metrics/logs. They are integrated into the Azure Portal and support auto refresh. They can be shared with specific users through Azure RBAC. Just like Insights, data from the metrics timeseries database, Log Analytics and activity logs can be aggregated by Dashboards.

#### Workbooks

These are like Dashboards except that their purpose is to analyze the data instead of displaying it. Unlike Dashboards, these do not support Azure RBAC.

#### Prometheus and Grafana

It is possible to load metric data into Prometheus from Log Analytics and create dashboards for the data using Grafana.

#### Power BI

This tool can be used to run powerful queries against the data in Log Analytics.

#### Kusto queries

It is possible to create and run custom queries in the Kusto Query Language against data in Log Analytics.

### Alerting

Events recorded in Activity logs, metrics from the time series Metrics database and results of queries on the Log Analytics can all be processed by alert rules and an alert raised if certain conditions are met.

Alerts can be viewed in a dashboard provided by the Azure Portal.

Static alerts are those that are raised when a static threshold value is violated. Dynamic alerts are those for which artificial intelligence techniques are used to determine abnormal threshold values.

Typically, alerts are processed by action rules which process alerts in the context of a scope (say a particular set of resources) and of a specified priority. If certain conditions are met, the action rule can trigger the execution of an action group which is simply a set of actions. These could be sending an SMS, sending an email, executing some automation, or raising an ITSM incident ticket. It is also possible to configure the action rule to suppress the action group for certain situations such as, say a planned maintenance window.

## Azure Traffic Analytics

Traffic Analytics is a cloud-based solution that provides visibility into user and application activity in cloud networks. Traffic analytics analyzes Network Watcher network security group (NSG) flow logs to provide insights into traffic flow in a customer's Azure environment. Traffic analytics can:

-   Visualize network activity across Azure subscriptions and identify hot spots.

-   Identify security threats to, and secure the network, with information such as open-ports, applications attempting internet access, and virtual machines (VM) connecting to rogue networks.

-   Understand traffic flow patterns across Azure regions and the internet to optimize network deployment for performance and capacity.

-   Pinpoint network misconfigurations leading to failed connections in the network.

The following diagram illustrates the components involved in the solution involving Traffic Analytics.

<center><img style="height:200;width:150" src="../images/nwtopo-traffic-analytics.svg" /></center>

Network Watcher is needed to turn on the generation of raw flow logs for an NSG and configuring a Storage Account to hold the raw flow logs. It also set up Traffic Analytics and associates it with a Logic Analytics workspace which holds the aggregated and indexed data that Traffic Analytics generates from the raw flow logs. Finally the Traffic Analytics solution provides various queries to help diagnose network issues.

## Security Management Architecture

This section presents an architectural overview of the security solution in Azure. The intent is to give the readers a high-level understanding of the various components involved in the enablement of security at the various layers of Azure and how these components complement one another in providing a comprehensive solution. The diagram below illustrates the architecture.

 <center><img style="height:200;width:150" src="../images/landingzone-loganalytics-sentinal.png" /></center>

### Log Analytics Workspace

This is a centralized workspace that gathers all the various logs across the Azure environment for a customer. Along with the Azure AD logs, subscription activity logs, VM logs and possibly PaaS logs other Azure and non-Azure data sources can also be leveraged via data connectors.

The proposed architecture shows the workspace as being shared between two other components â€“ Azure Security Center (ASC) and Azure Sentinel. While it is possible to deploy a separate workspace for each of these components, a shared workspace is proposed to avoid duplicate data and the associated cost.

### Azure Policy

This component provides bundles of policies, called initiatives, that specify the controls a customerâ€™s environment and workloads in Azure need to adhere to. These initiatives are communicated to another component, the Azure Security Center, that then monitors for violation of the associated policies. These initiatives often include policies in support of industry and regulatory compliances such as CIS Benchmarks, PCI DSS and HIPAA.

### Azure Security Center (ASC)

ASC is a unified infrastructure security management system that â€“

Â·    Proactively assesses a customerâ€™s environment and workloads against the enabled policies

Â·    Identifies potential security risks and recommends a course of action to mitigate

Â·    In certain cases, it provides remediation in the form of quick fixes

Â·    Supports workflow automation through Logic Apps that can perform notification as well as remediation

ASC obtains a large part of the data it needs to monitor the environment and workload via Azure backend telemetry. It only relies on the Log Analytics workspace for VM logs.

### Azure Defender

This component extends the capability of ASC to protect customer workloads. Defender combined with ASC Base Edition gives the ASC Standard Edition. It provides the following advanced solutions â€“

Â·   VM vulnerability assessment via the Qualys tool

Â·   Just-in-Time VM access

Â·   Adaptive Application Controls leverage Machine Learning to determine a list of safe software on a VM and enable Defender to detect suspicious software

Â·   Container image scanning to detect vulnerabilities

Â·   Adaptive network hardening uses Machine Learning to analyze network traffic patterns and determine further tightening of the NSG rules

Â·   SQL vulnerability assessment analyses SQL Server configurations to detect vulnerabilities

Â·   File integrity monitoring detects and reports suspicious changes to files on a VM

Â·   Network map that graphically displays network topologies to inform on traffic flows and any security risk such as lack of NSGs for subnets

### Azure Sentinel

This component provides Security Incident and Event Management (SIEM) and Security Orchestration Automated Response (SOAR) function for Azure environments. In addition to the logs from all Azure services and resources, the events and alerts it obtains from ASC via the shared Log Analyzer workspace, it also provides data connectors so many non-Azure components can also input data into the Log Analyzer workspace used by Sentinel.

Sentinel basically correlates all the data it receives using Machine Intelligence to detect security threats and generates alerts in response. It also supports tools that can be used to recover from these security threats. Its notable features are â€“

Â·   Many pre-built rules based on Kusto queries of the data in the Log Anaytics workspace to detect certain conditions and raise alerts

Â·   Many pre-built playbooks to automate the performance of tasks such as blocking a user, blocking an IP address upon detection of certain conditions

Â·   Many pre-built workbooks to perform various types of computation 

Â·   Hunting capability to find occurrences of certain conditions in the received data

Â·   Many pre-built notebooks that enhance the Machine Learning capabilities

Â·   Entity behaviour analysis to identify anomalous behaviour patterns indicative of a security attack

Â·    Ability to enhance a database of threats with new ones

## Log Analytics Workspace

While this component has been described briefly in different contexts, it is core to all of monitoring as the diagram below illustrates. 

<center><img style="height:200;width:150" src="../images/monitoring-la-workspace.svg" /></center>

The purpose of this section is to provide more details on this component to serve as a basis for laying out design considerations and recommendations.

### Deployment Models

In general, three deployment models are possible for this component -

**Centralized**: Single central workspace with differentiated access per team. Easy to manage, search across resources, and cross-correlate logs. Workspace size can grow significantly. Additional administrative overhead to maintain access control to different users. Cost of transporting data when the workspace spans multiple regions needs to be considered.

**Decentralized**: Multiple workspaces across regions, subscriptions and resource groups. Access control to resources is possible but cross-correlation across multiple logs will be difficult.

**Hybrid**: Complex, expensive, and hard-to-maintain configuration with gaps in logs coverage.

### Access Control for Resources

Log Analytics workspaces now support a new resource-context log model wherein every log record emitted by an Azure resource is automatically associated with this resource. Such logs when forwarded to a central workspace enable scoping and Azure RBAC based on the resources.

Depending on the context, a user may have either a workspace-context mode or a resource-context mode. For example, when examining metrics for all VMs, the workspace-context mode is assumed and when examining metrics for a particular VM, the resource-context mode is assumed. 

The Access control mode is a setting on each workspace that defines how permissions are determined for the workspace. Log Analytics workspaces can require workspace permissions only or use either workspace or resource permissions. The latter option enables fine grain access control through Azure RBAC the downside being the need to set the resource-level permissions for users. 

When a workspace has only workspace permissions there is no RBAC-based access control and the behavior is as follows

- a user with workspace-context mode can access all the tables in the workspace that it has been granted access to
- a user with resource-context mode can access only the data for those resources it has been granted access to

When a workspace has both workspace and resource permissions, RBAC-based access control takes effect and the behavior is as follows

- a user with workspace-context mode can be given access based on the workspace permissions
- a user with resource-context mode can be given access based on the resource permissions

For a more details on the deployment models and access control for Log Analytics workspace, please refer to the information at

[Designing your Azure Monitor Logs deployment](https://docs.microsoft.com/en-us/azure/azure-monitor/logs/design-logs-deployment).



## Update Management

Azure provides the Update Management service for Windows VMs as well as Linux VMs for some popular distributions. Windows VMs are generally configured to use Microsoft Update while Linux VMs are generally configured to use the public repositories specific to the distributions. These are the sources for information on availability of patches.

Both Windows and Linux VMs report their patch status as well as available patches via the Log Analytics agent to a Log Analytics workspace. The information can be used by Update Management to schedule select patches to groups of VMs at a certain time.  

An Automation Account is a service that supports automation of tasks, updates being one, through runbooks. Update Management schedules updates using runbooks in an Automation Account.

## Resource Locks 

A Resource Lock is not technically a policy, but the purpose is similar in the fact that it will prevent accidental modification and/or deletion, of subscription, resources groups or resources. 

There are two types of locks: 

o  **CanNotDelete** means authorized users can still read and modify a resource, but they canâ€™t delete the resource. 

o  **ReadOnly** means authorized users can read a resource, but they canâ€™t delete or update the resource. Applying this lock is like restricting all authorized users to the permissions granted by the Reader role. 

 When you apply a lock at a parent scope, all resources within that scope inherit the same lock. Even resources you add later inherit the lock from the parent. The most restrictive lock in the inheritance takes precedence. 

Unlike role-based access control, you use management locks to apply a restriction across all users and roles. 

Applying Read-only can lead to unexpected results because some operations that seem like read operations require additional actions. For example, placing a ReadOnly lock on a storage account prevents all users from listing the keys. The list keys operation is handled through a POST request because the returned keys are available for write operations. For another example, placing a ReadOnly lock on an App Service resource prevents Visual Studio Server Explorer from displaying files for the resource because that interaction requires write access. 

## Centralized Cloud Platform Management 

For all Kyndryl managed accounts, centralized monitoring and management platform is recommended. It requires the use of Azure native tools as well as Kyndrylâ€™s recommended ITOM (IT Operations Management) and ITSM (IT Service Management) tools. The high-level architecture of centralized monitoring and management solution is as below

<center><img style="height:200;width:150" src="../images/landingzone-CMP.png" /></center>

The solution components are described below â€“

Â·   **Monitoring Layer**: It provides the centralized monitoring capabilities for the LZ, and the applications hosted in it.  Azure Monitor, Log Analytics Workspace, Azure Application insights provide native capability to monitor the LZ infrastructure. Additional Enterprise monitoring tools like ScienceLogic, Datadog are recommended to monitor the components needed for the application. E.g if an Oracle or DB2 database running on a VM. The subsystems running on a VM cannot be monitored by Native monitoring tools.

Â·   **Event Aggregation Layer**:  The various monitoring and audit events generated at the monitoring layer needs to be aggregated at event management layer to avoid duplicate tickets and noise in the management system. This layer also triggers the event automations to auto remediate the incidents.

Â·   **Automation Layer**: It provides automation capability for Day-1 provisioning tasks and Day-2 operational tasks. Discovery service will discover the managed resources and sync the CMDB.

Â·   **Service Management Layer**: This layer provides the IT Service management capability for IPC (Incident, Change and Problem). This is the primary system to manage the cloud environment. The automations for service requests, change requests can be triggered from this layer. It also provides the self-service catalog for the end users to provision the cloud resources in the target LZ.

Â·   **Automation Framework**: It is recommended to have a common automation framework like Ansible based CACF framework. Cloud native automations can also be used to automate repetitive tasks and the processes.

**NOTE -** It is to be noted that at this time, it is unclear how the the three upper layers in the stack above - Service Management, Automation Layer and Event Aggregation Layer will be designed and implemented. A number of options are being examined and the integration of the Azure platform with these management layers will be clearer once the choice is made as to which option to go forward with.

## Centralized Monitoring & Management by MCMS

MultiCloud Management Services (MCMS) offering provides monitoring and management services for Clientâ€™s Azure LZ. It is a shared service offering. The tools and processes needed to manage clientâ€™s Azure environment will be hosted on **Kyndryl MCMS Tools Pod** and **Kyndryl MCMS MSP subscription**. The reference architecture is as shown below.

<center><img style="height:200;width:150" src="../images/landingzone-centralmonitoring-management.png" /></center>

This Kyndryl MSP subscription will contain:

**a)**  **Transit-Hub vNet**

- This Transit-Hub vNet is connected to Kyndrylâ€™s management pod using IPSec Tunnel 

**b)**  **Transit-Client vNet**

- For each client subscription there will be a Transit vNet
- Transit-Client vNet contains Bastion host for Kyndryl support teams to connect to target services In each client subscription
- Transit-Client vNet also contains Proxy &/or Relay servers to pass traffic from/to Azure native tools to Kyndryl tools in the management pod.
- Each Transit-Client vNet will connect to respective clientâ€™s Hub vNet either through **vNet peering or site-to-site VPN**. vNet peering will be **default** whereas site-to-site VPN will be used for regulated accounts and if a client security requirement demands this.
- IP address range for Transit-client vNet can overlap with that of another Transit-client vNet. This is because 
  - Transit-client VNets do not communicate amongst themselves 
  - When Transit-client vNets communicate to Transit-Hub vNets, NAT is implemented at the Transit-Hub to differentiate each of the Transit-Client vNets
- IP address range for Transit-client vNets cannot overlap with client Hub vNet, and hence has to be discussed with respective clients to provide a x.x.x.x/26 IP address range 

## Azure Lighthouse

To provide centralized cloud management services for multiple clients, MCMS needs a cloud native service called Lighthouse. It enables cross- and multi-tenant management, allowing for higher automation, scalability, and enhanced governance across resources and tenants. With Azure Lighthouse, service providers can deliver managed services using comprehensive and robust management tooling built into the Azure platform.

Â·   It provides built-in options for centralized access across organizations (tenants & subscriptions)

Â·   Azure Lighthouse will be included as part of Kyndrylâ€™s centralized Cloud management services.

Â·   Specific guidance on enabling this will be included in future releases. 

## Centralized Monitoring & Management Environment â€“ ISPwW & traditional SO

Â·   For non-MCMS managed accounts, management PoD should be hosted in ISPwW or in traditional Strategic Outsourcing (SO) environments.

Â·   Similar model used for MCMS can be applied on ISPwW & SO accounts too

Â·    Guidance for this will be added in the next release.

## Solution Guidance

This sub-section provides guidance at a high level on the key design considerations and best practices for designing a monitoring and management platform for Azure resources.

### Design Considerations

Following are the main design considerations for monitoring and management -

- The appropriate deployment model for Log Analytics workspace needs to be chosen based on customer requirements
- Address the need for detection and notification of abnormal events at the IaaS level
- Address the need for detection and notification of abnormal events at the SQL Server that is running on either Managed Instances or Iaas VMs
- Address the need for detection and notification of abnormal events at the third-party middleware and database level
- Assess and identify security risks and provide for detection, response, and recovery from threats
- Potential integration with on-premises security information and event management (SIEM) systems such as ServiceNow, ArcSight, or the Onapsis security platform
- Monitor network flows for potential issues
- Support the timely deployment of patches to VMs to minimize security risks.
- Azure data retention thresholds and archiving requirements:
  - The default retention period for Azure Monitor Logs is 30 days, with a maximum of two years
  - The default retention period for Azure AD reports (premium) is 30 days
  - The default retention period for the Azure diagnostic service is 90 days.
- Operational requirements - Resource locks to protect editing and deleting resource.

##Design Actions by Solution Architects. 


1. In alignment with recent Microsoft recommendations, define a single Log Analytics workspace per region to simplify administration, avoid additional cost from log replication across workspaces and enable correlation across a wide set of inputs.   

	Where multiple regions are used, create one Log Analytics workspace in each region to avoid the cost from data transfer across regions

2. Add integration with MCMS or Kyndryl SO delivery for Event correlation, Event Automation & ITSM integrations, which will cover the following:    
	a. Configure alerts for standardized metrics and associated thresholds for IaaS resources using the Azure Monitor metrics database. Alerts are conveyed to MCMS for incident ticket creation and potential automated remediation

	b. Configure alerts for VM and SQL metrics for SQL Server using both the Azure Monitor metrics database and the Azure Monitor Log Analytics workspace.  Alerts are conveyed to MCMS for incident creation and potential automated remediation

	c. Deploy third party monitoring solutions as needed, such as Science Logic for middleware and third-party databases and to also configure alerts. Alerts are conveyed to MCMS for incident creation and potential automated remediation

3. Include Azure Security Center and Azure Sentinel for assessing compliance and identifying security risks and for detection, response and recovery from threats. Alerts raised by Sentinel are conveyed to MCMS/SO delivery tools for incident creation and potential automated remediation.  

	Integration of Azure Sentinel with on-premises SIEM should be limited to communicating alerts

4. Include Azure Policy for configuring access control and compliance reporting. Azure Policy provides the ability to enforce organization-wide settings to ensure consistent policy adherence and fast violation detection

5. Use Network Watcher to proactively monitor traffic flows via [Network Watcher NSG flow logs v2](https://docs.microsoft.com/en-us/azure/network-watcher/network-watcher-nsg-flow-logging-overview).  

	[Traffic Analytics](https://docs.microsoft.com/en-us/azure/network-watcher/traffic-analytics) analyzes NSG flow logs to gather deep insights about IP traffic within a virtual network and provides critical information for effective management and monitoring. It can support queries that can then trigger alerts

6. Use [Update Management in Azure Automation](https://docs.microsoft.com/en-us/azure/automation/update-management/overview) as a long-term patching mechanism for both Windows and Linux VMs.   

	- Enforcing Update Management configurations via Azure Policy ensures that all VMs are included in the patch management regimen and provides application teams with the ability to manage patch deployment for their VMs.  
	- Integrate Azure Update Management into service flow implemented as part of MCMS tooling to support triggering of updates and their approvals.  
	- For Kyndrly accounts ensure the MCMS/SO delivery service flow is synchronized with Risk based Continuous Patch Tracking (RCP). RCP provides visibility and enforcement capabilities to the central compliance team.  

7. Export logs to Azure Storage if log retention requirements exceed two years. Use immutable storage with a write-once, read-many policy to make data non-erasable and non-modifiable for a user-specified interval.  

8. Operational requirements: Define resource locks to prevent accidental deletion of critical shared services.  

## Additional Notes

It is to be noted that MCMS integration with Azure is in progress. So all features and functions mentioned in the context of MCMS need to be validated with the MCMS Offering team.



